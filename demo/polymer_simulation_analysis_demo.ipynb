{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed325809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.datasets import make_blobs\n",
    "from scipy.cluster.hierarchy import centroid, fcluster\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.cluster.hierarchy import ward, median, centroid, weighted, average, complete, single, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "import scipy.spatial.distance as ssd\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import math\n",
    "\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88f6469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we find radial and peripheral distribution of the cluster centroids for Oblate0.33 case at energy level E4\n",
    "\n",
    "def import_data(file_name):\n",
    "        data = pd.read_csv(file_name, skiprows=9, names=['id', 'x', 'y', 'z', 'ix', 'iy' ,'iz'] , sep=\" \", header=None)\n",
    "        df = pd.DataFrame(data)\n",
    "        df_filtered_polymer =  df[df['id'] > 630]\n",
    "        return  df_filtered_polymer[['x', 'y', 'z']]\n",
    "    \n",
    "def import_wall(file_name):\n",
    "        data = pd.read_csv(file_name, skiprows=9, names=['id', 'x', 'y', 'z', 'ix', 'iy' ,'iz'] , sep=\" \", header=None)\n",
    "        df = pd.DataFrame(data)\n",
    "        df_filtered_wall =  df[df['id'] < 631]\n",
    "        return  df_filtered_wall[['x', 'y', 'z']]    \n",
    "\n",
    "def run_agglomerated_clustering(df):\n",
    "    hac=hc.fit(df)\n",
    "    membership = hac.labels_\n",
    "    return membership \n",
    "\n",
    "def filter_cluster(df, membership):\n",
    "    df = df.copy().reset_index(drop=True)\n",
    "    df[\"label\"] = membership\n",
    "    cluster_sizes = df.groupby(\"label\").count()[\"x\"].to_dict()\n",
    "    df[\"size\"] = df[\"label\"].apply(lambda id: cluster_sizes[id])\n",
    "    return df[ ( (df['size'] > 1)) ]\n",
    "\n",
    "\n",
    "def myfunction(x):\n",
    "    return math.sqrt(x[0]**2 + x[1]**2 + x[2]**2)\n",
    "\n",
    "def min_dis_wall(x):\n",
    "    return x\n",
    "    \n",
    "    \n",
    "\n",
    "#folder_path = '/Users/negarna/Dropbox (UiO)/clustering_data_new3/Oblate0.33/no_colloids/quadruple_energy/'\n",
    "folder_path = '/Users/negarna/Desktop/Data_Availability_Oda/'\n",
    "j=1500000000\n",
    "imax=2*10**9\n",
    "np.set_printoptions(floatmode='unique')\n",
    "individual_clusters_by_size = []\n",
    "num_of_clusters_per_file = []\n",
    "Centroids_dis = []\n",
    "Centroids_periphery = []\n",
    "min_peri2 = []\n",
    "all_centroids = []\n",
    "iterator = 0\n",
    "# defining the clustering model\n",
    "hc = AgglomerativeClustering(n_clusters=None, affinity='euclidean', linkage='single', distance_threshold=0.970)\n",
    "file_list = glob.glob(folder_path + \"qua.*\")\n",
    "\n",
    "for i in range(1,len(file_list)):\n",
    "    file_name = folder_path + \"qua.dump.\"+ str(j)\n",
    "    df = import_data(file_name)\n",
    "    membership = run_agglomerated_clustering(df)\n",
    "    df_filtered = filter_cluster(df, membership)\n",
    "    \n",
    "    clf = NearestCentroid(metric='euclidean')\n",
    "    clf.fit(df_filtered[[\"x\", \"y\", \"z\"]], df_filtered[['label']])\n",
    "    rr = np.apply_along_axis(myfunction, axis=1, arr=clf.centroids_)\n",
    "    Centroids_dis.extend(rr)\n",
    "    all_centroids.extend(clf.centroids_)\n",
    "    ############## PERIPHERY\n",
    "    np_wall = import_wall(file_name).to_numpy()\n",
    "    dis_peri = np.ndarray(630,float) \n",
    "    for ii in range(0,len(clf.centroids_)):\n",
    "        for jj in range(0,630):\n",
    "            dis_peri[jj] = np.sqrt((clf.centroids_[ii,0]-np_wall[jj,0])**2 + (clf.centroids_[ii,1]-np_wall[jj,1])**2 + (clf.centroids_[ii,2]-np_wall[jj,2])**2)\n",
    "        min_p = float(np.round(min(dis_peri).astype(np.float64), 3))\n",
    "        min_peri2.append(min_p)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    " \n",
    "    j = j + 50000000\n",
    "    if j>imax:\n",
    "        break   \n",
    "all_C = np.array(all_centroids)\n",
    "centroid_loc = pd.DataFrame(all_C, columns = ['x','y','z'])\n",
    "\n",
    "Centroids_dis = np.array(Centroids_dis)\n",
    "\n",
    "min_peri2 = [x -1 for x in min_peri2]\n",
    "\n",
    "df_rp_Oblate13_E4 = pd.DataFrame({'r':Centroids_dis, 'p':min_peri2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673db8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "centroid_clustering",
   "language": "python",
   "name": "centroid_clustering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
